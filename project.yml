title: "LiBERTus - A Multilingual Language Model for Ancient and Historical Languages"
description: |
  Submission to Task 1 (Constrained) of the [SIGTYP 2024 Shared Task on Word
  Embedding Evaluation for Ancient and Historical
  Languages](https://sigtyp.github.io/st2024.html)

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories:
  - "assets"
  - "corpus"
  - "metrics"
  - "packages"
  - "pretraining"
  - "scripts"
  - "tokenizer"
  - "training"

vars:
  version: 0.1.0
  # Project
  remote_gcs_bucket: "ljvmiranda"
  hf_repo: "ljvmiranda921/LiBERTus"
  publish_message: "Update SIGTYP pipeline"
  # Pretraining params
  seed: 42
  batch_size: 64
  max_steps: 100000
  save_steps: 1000
  model_size: "base"
  learning_rate: 0.0002
  sampling_strategy: "upsample"
  evaluation_corpus: "corpus/evaluation.txt"
  pretraining_corpus: "corpus/pretraining.txt"
  # Finetuning params
  nlp_lang: "xx"
  config: "transformer.cfg"
  base_model: "ljvmiranda921/LiBERTus-base"
  train_lang: "chu"
  dev_lang: "chu"
  test_lang: "chu"
  gpu_id: 0
  # Training logs
  name: "main"
  wandb_project: "sigtyp2024"

env:
  HUGGINGFACE_TOKEN: HUGGINGFACE_TOKEN
  WANDB_LOG_MODEL: WANDB_LOG_MODEL

remotes:
  # Create a service account, download a JSON key, and set the credentials path
  # to GOOGLE_APPLICATION_CREDENTIALS env variable
  gcs: "gs://${vars.remote_gcs_bucket}/research/LiBERTus/training_cache/v${vars.version}/"

# Assets that should be downloaded or available in the directory. But the
# 'weasel assets' command still lets you verify that the checksums match.
assets:
  - dest: assets/train/
    git:
      repo: https://github.com/sigtyp/ST2024
      branch: main
      path: morphology/train
    description: "CoNLL-U training datasets for Task 0 (morphology/lemma/POS)"
  - dest: assets/dev/
    git:
      repo: https://github.com/sigtyp/ST2024
      branch: main
      path: morphology/valid
    description: "CoNLL-U validation datasets for Task 0 (morphology/lemma/POS)"
  - dest: assets/default_zh_model.zip
    url: https://github.com/lancopku/pkuseg-python/releases/download/v0.0.25/default_v2.zip
    description: "Model to use for pkuseg for Chinese"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "weasel run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  pretrain:
    - create-pretraining
    - create-vocab
    - pretrain-model
  finetune:
    - convert-to-spacy
    - finetune-trf-model
    - evaluate-model-dev
    # - evaluate-model-test
  experiment-merged:
    - convert-to-spacy-merged
    - finetune-with-merged-corpus
  experiment-sampling:
    - create-vocab
    - pretrain-model

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "weasel run [command] [path]". The help message is optional and
# shown when executing "weasel run [optional command] [path] --help".
commands:
  - name: "create-pretraining"
    help: "Create corpus for multilingual LM pretraining"
    script:
      - >-
        python -m scripts.convert_to_pretrain assets/dev 
        --output-path ${vars.evaluation_corpus} 
        --seed 42 
        --shuffle 
        --verbose
      - >-
        python -m scripts.convert_to_pretrain assets/train/ 
        --output-path ${vars.pretraining_corpus} 
        --seed ${vars.seed}
        --shuffle
        --verbose
    outputs:
      - ${vars.pretraining_corpus}
      - ${vars.evaluation_corpus}

  - name: "create-vocab"
    help: "Train a tokenizer to create a vocabulary"
    script:
      - python -m scripts.train_tokenizer ${vars.pretraining_corpus} tokenizer/
    deps:
      - ${vars.pretraining_corpus}
    outputs:
      - tokenizer/vocab.json
      - tokenizer/merges.txt

  - name: "pretrain-model"
    help: "Pretrain a multilingual LM from a corpus"
    script:
      - mkdir -p pretraining/${vars.model_size}/
      - >-
        python -m scripts.pretrain_model pretraining/${vars.model_size}/
        --name ${vars.name}
        --size ${vars.model_size}
        --pretraining-corpus ${vars.pretraining_corpus}
        --evaluation-corpus ${vars.evaluation_corpus} 
        --learning-rate ${vars.learning_rate}
        --vocab tokenizer/vocab.json
        --merges tokenizer/merges.txt
        --batch-size ${vars.batch_size}
        --max-steps ${vars.max_steps}
        --save-steps ${vars.save_steps}
        --seed ${vars.seed}
        --wandb-project ${vars.wandb_project}
    deps:
      - tokenizer/vocab.json
      - tokenizer/merges.txt
      - ${vars.pretraining_corpus}
    outputs:
      - pretraining/${vars.model_size}/model/config.json
      - pretraining/${vars.model_size}/model/model.safetensors
      - pretraining/${vars.model_size}/model/training_args.bin

  - name: "pretrain-model-from-checkpoint"
    help: "Pretrain a multilingual LM from a corpus based on a checkpoint"
    script:
      - mkdir -p pretraining/${vars.model_size}/
      - >-
        python -m scripts.pretrain_model pretraining/${vars.model_size}/
        --resume-from-checkpoint
        --name ${vars.name}
        --size ${vars.model_size}
        --pretraining-corpus ${vars.pretraining_corpus}
        --vocab tokenizer/vocab.json
        --merges tokenizer/merges.txt
        --batch-size ${vars.batch_size}
        --max-steps ${vars.max_steps}
        --save-steps ${vars.save_steps}
        --seed ${vars.seed}
        --wandb-project ${vars.wandb_project}
    deps:
      - tokenizer/vocab.json
      - tokenizer/merges.txt
      - ${vars.pretraining_corpus}
    outputs:
      - pretraining/${vars.model_size}/model/config.json
      - pretraining/${vars.model_size}/model/model.safetensors
      - pretraining/${vars.model_size}/model/training_args.bin

  - name: "upload-to-hf"
    help: "Upload pretrained model and corresponding tokenizer to the HuggingFace repository"
    script:
      # Upload the models and tokenizer
      - huggingface-cli upload ${vars.hf_repo}-${vars.model_size} pretraining/${vars.model_size}/model/ .
      - huggingface-cli upload ${vars.hf_repo}-${vars.model_size} tokenizer/ .
      # Upload pretraining data (for reproducibility)
      - huggingface-cli upload ${vars.hf_repo}-${vars.model_size} corpus/pretraining.txt pretraining.txt
    deps:
      - tokenizer/vocab.json
      - tokenizer/merges.txt
      - corpus/pretraining.txt
      - pretraining/${vars.model_size}/model/config.json
      - pretraining/${vars.model_size}/model/model.safetensors
      - pretraining/${vars.model_size}/model/training_args.bin

  - name: "convert-to-spacy-merged"
    help: "Convert CoNLL-U files into spaCy format for finetuning"
    script:
      # Remove erroneus files first from corpus
      - mv assets/train/ohu_train.conllu .
      - mv assets/train/orv_train.conllu .
      - mv assets/dev/orv_valid.conllu .
      # Concatenate everything for experiment
      - mkdir -p corpus/merged_train/
      - python -m spacy convert assets/train/ corpus/merged_train/ --morphology --concatenate
      - mkdir -p corpus/merged_dev/
      - python -m spacy convert assets/dev/ corpus/merged_dev/ --morphology --concatenate
    deps:
      - assets/train/
      - assets/dev/
    outputs:
      - corpus/merged_train/train.spacy
      - corpus/merged_dev/dev.spacy

  - name: "convert-to-spacy"
    help: "Convert CoNLL-U files into spaCy format for finetuning"
    script:
      # Remove erroneus files first from corpus
      - mv assets/train/ohu_train.conllu .
      - mv assets/train/orv_train.conllu .
      - mv assets/dev/orv_valid.conllu .
      # Convert each language
      - mkdir -p corpus/train
      - python -m spacy convert assets/train/ corpus/train/ --morphology
      - mkdir -p corpus/dev
      - python -m spacy convert assets/dev/ corpus/dev/ --morphology
    deps:
      - assets/train/
      - assets/dev/
    outputs:
      - corpus/train/
      - corpus/dev/

  - name: "finetune-tok2vec-model"
    help: "Finetune a tok2vec model given a training and validation corpora"
    script:
      - mkdir -p training/${vars.train_lang}/
      - >-
        python -m spacy train configs/default.cfg
        --nlp.lang ${vars.nlp_lang}
        --output-path training/${vars.train_lang}/
        --paths.train corpus/train/${vars.train_lang}_train.spacy
        --paths.dev corpus/dev/${vars.dev_lang}_valid.spacy
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
    deps:
      - corpus/train/${vars.train_lang}_train.spacy
      - corpus/dev/${vars.dev_lang}_valid.spacy
    outputs:
      - training/${vars.train_lang}/model-best/
      - training/${vars.train_lang}/model-last/

  - name: "finetune-trf-model"
    help: "Finetune a transformer model given a training and validation corpora"
    script:
      - mkdir -p training/${vars.train_lang}/
      - >-
        python -m spacy train configs/${vars.config}
        --nlp.lang ${vars.nlp_lang}
        --output-path training/${vars.train_lang}/
        --paths.train corpus/train/${vars.train_lang}_train.spacy
        --paths.dev corpus/dev/${vars.dev_lang}_valid.spacy
        --components.transformer.model.name ${vars.base_model}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
    deps:
      - corpus/train/${vars.train_lang}_train.spacy
      - corpus/dev/${vars.dev_lang}_valid.spacy
    outputs:
      - training/${vars.train_lang}/model-best/
      - training/${vars.train_lang}/model-last/

  - name: "finetune-with-merged-corpus"
    help: "Finetune a transformer model on the combined training and validation corpora"
    script:
      - mkdir -p training/merged/
      - >-
        python -m spacy train configs/transformer.cfg
        --output-path training/merged/
        --paths.train corpus/merged_train/train.spacy
        --paths.dev corpus/merged_dev/dev.spacy
        --components.transformer.model.name ${vars.base_model}
        --system.seed ${vars.seed}
        --gpu-id ${vars.gpu_id}
    deps:
      - corpus/merged_train/train.spacy
      - corpus/merged_dev/dev.spacy
    outputs:
      - training/merged/model-best/
      - training/merged/model-last/

  - name: "package-model"
    help: "Package model and upload to HuggingFace"
    script:
      - >-
        python -m spacy package
        training/${vars.train_lang}/model-best/ packages/
        --name ${vars.train_lang}_sigtyp_trf
        --version ${vars.version}
        --build sdist,wheel
        --force
      # Upload to HuggingFace
      - huggingface-cli login --token ${env.HUGGINGFACE_TOKEN}
      - >-
        python -m spacy huggingface-hub push packages/${vars.nlp_lang}_${vars.train_lang}_sigtyp_trf-${vars.version}/dist/${vars.nlp_lang}_${vars.train_lang}_sigtyp_trf-${vars.version}-py3-none-any.whl
        --msg "${vars.nlp_lang}_${vars.train_lang}_sigtyp_trf-${vars.version}: ${vars.publish_message}"
        --verbose
    deps:
      - training/${vars.train_lang}/model-best/
    outputs:
      - packages/${vars.nlp_lang}_${vars.train_lang}_sigtyp_trf-${vars.version}/dist/${vars.train_lang}_sigtyp_trf-${vars.version}.tar.gz
      - packages/${vars.nlp_lang}_${vars.train_lang}_sigtyp_trf-${vars.version}/dist/${vars.train_lang}_sigtyp_trf-${vars.version}-py3-none-any.whl

  - name: "evaluate-model-dev"
    help: "Evaluate a model on the validation set"
    script:
      - mkdir -p metrics/system_scores/${vars.train_lang}/
      - >-
        python -m spacy evaluate
        training/${vars.train_lang}/model-best/ corpus/dev/${vars.dev_lang}_valid.spacy
        --output metrics/system_scores/${vars.train_lang}/metrics-${vars.dev_lang}-dev.json
        --per-component
        --gpu-id ${vars.gpu_id}
    deps:
      - training/${vars.train_lang}/model-best/
      - corpus/dev/${vars.dev_lang}_valid.spacy
    outputs:
      - metrics/system_scores/${vars.train_lang}/metrics-${vars.dev_lang}-dev.json

  - name: "evaluate-model-test"
    help: "Evaluate a model on the test set"
    script:
      - mkdir -p metrics/system_scores/${vars.train_lang}/
      - >-
        python -m spacy evaluate
        training/${vars.train_lang}/model-best/ corpus/test/${vars.test_lang}_test.spacy
        --output metrics/system_scores/${vars.train_lang}/metrics-${vars.test_lang}-test.json
        --per-component
        --gpu-id ${vars.gpu_id}
    deps:
      - training/${vars.train_lang}/model-best/
      - corpus/test/${vars.test_lang}_test.spacy
    outputs:
      - metrics/system_scores/${vars.train_lang}/metrics-${vars.test_lang}-dev.json

  - name: "plot-figures"
    help: "Plot figures for the writeup"
    script:
      - python -m scripts.plotters.plot_training_curve metrics/wandb_train_curve_main.csv paper/figures/train_loss.pdf
      - python -m scripts.plotters.plot_token_counts metrics/tokens_upsampling.csv paper/figures/token_counts.pdf
      - python -m scripts.plotters.plot_crosseval_heatmap metrics/system_scores/ paper/figures/cross_lingual.pdf
      - python -m scripts.plotters.plot_comparison metrics/system_scores/ metrics/hashembed_scores/ paper/figures/hashembed.pdf --ours-name "RoBERTa-based (ours)" --theirs-name "Multi hash embeddings"
      - python -m scripts.plotters.plot_comparison metrics/system_scores/ metrics/monolithic_scores/ paper/figures/monolithic.pdf --ours-name "Language-specific (ours)" --theirs-name "Monolithic"
    outputs:
      - paper/figures/train_loss.pdf
      - paper/figures/token_counts.pdf
      - paper/figures/cross_lingual.pdf
      - paper/figures/hashembed.pdf
